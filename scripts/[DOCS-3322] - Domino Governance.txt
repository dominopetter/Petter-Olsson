Domino AI Governance  |    


________________


Domino Governance[a]
Pre-Release Documentation
1- Domino Governance
Domino governance refers to the frameworks, policies, and guidelines that oversee the development, deployment, and use of artificial intelligence technologies. Domino governance makes sure that these are aligned with corporate policies and societal values. 
This involves a multidisciplinary approach: combining technical, legal, and ethical perspectives to address issues like bias, privacy, accountability, and transparency. s
About this release
You are getting access to a pre-release version of Domino governance. This will help you familiarize yourself with the new concepts and provide feedback. However, there is no guarantee that what is implemented today will be fully compatible with the GA release coming this fall.
  

________________


Table of Contents
1- Domino Governance        1
1.1 - Challenges of governance        3
1.2 - How Domino enables governance        4
2 - High-level overview        5
2.1 - Policies        5
2.1.1 - Stages        5
2.1.2 - Evidence sets        6
2.1.3 - Approvals        6
2.1.4 - Classification        6
2.2 - Governed Bundle        7
2.2.1 - Attachments        7
2.2.2 - Evidence notebook        7
3 - Roles and permissions        8
3.1 - GovernanceAdmin        8
4 - Building and managing policies        9
4.1 - Policy Definition (YAML)        9
4.1.1 - Structure Overview        9
4.1.2 - Stages        9
4.1.3 - Evidence and evidence sets        10
4.1.4 - Input Artifacts        11
4.1.5 - Guidance Artifacts        14
4.1.6 - Approvals        15
4.1.7 - Classification        16
Getting Started        18
Building a policy        18
Governing ML & AI and Statistical Analysis        18
Best practices        19
API definition        19
Industry-specific use cases (Pharma, FSI, Public Sector)        19
________________
1.1 - Challenges of governance 
When an organization attempts to govern scientific output—either with traditional machine learning models, generative AI systems, or statistical analysis—it often faces similar challenges. 
* Completeness and timeliness: Evidence collection is manual and spread across systems, often reviewed too late - after the work is complete. This delay forces scientific teams to backtrack and gather information that was initially available during development, hindering innovation and slowing down deployment.
* Fragmented policies: Each enterprise has unique, overlapping, and constantly evolving policies and requirements. Keeping up with these changes and accurately mapping which policy governs each scientific output demands significant dedication and precision.
* Complex enforcement: Enforcing diverse policies in evolving, bespoke environments is challenging. With overlapping policies that evolve independently, ensuring compliance through the correct workflows can be difficult, potentially hindering both innovation and the overall efficiency of the organization.
* Missing context: The absence of model lineage, KPIs, and work context leads to delays in approvals and audits, forcing teams to search for information, which further delays progress.
________________
1.2 - How Domino enables governance 
Governance is a systematic approach to integrating scientific output into a compliant development process. 
* Integrated governance interface: The evidence notebook embedded within Domino’s workbench enables scientists to document evidence as it becomes available and when needed. Reviewers benefit from a comprehensive view of the workbench, allowing them to inspect the provided evidence alongside a complete 360-degree perspective of the code, data, environment, metrics, and more.
* Unified system of record: Domino’s unified system of record provides a bidirectional view of all artifacts used and generated. For each model, it automatically captures the data used for training, the code executed, and the environment and hardware on which execution occurs. With the Domino governance add-on, it also records all evidence related to a scientific output (referred to as a ‘governed bundle’) within the context of a specific policy.
* Dynamic workflow engine: When implementing a new policy to govern scientific output, the process is often divided into stages with multiple evidence collection requests, specific sequential approvals, and support for complex conditions.
* Governance dashboard: Domino governance offers a single source of truth for compliance, providing a single pane of glass of all governed bundles, like models or AI systems, and their compliance status with respect to each applicable policy.
________________


2 - High-level overview
Some of the core concepts that were introduced with Domino governance are described below.
  

2.1 - Policies 
Policies are translations of regulations, like the EU AI Act, frameworks like NIST AI RMF,[b] or internal policies. In Domino, you express your policies in a YAML document so they can be interpreted and enforced by Domino’s policy engine. 
A policy is composed of one or more stages. Each stage can request any number of evidence sets, which are composed of different types of evidence and provide answers to policy questions. 
2.1.1 - Stages
Stages are key milestones, meaningful phases of work, in a policy. For example, in a model risk management policy, the stages could be: 
1. Develop business case
2. Define requirements
3. Model development and testing
4. Model validation
5. Model deployment
6. Model monitoring
2.1.2 - Evidence sets
An evidence set consists of groupings of evidence. It can be re-used within a policy or across policies. Evidence sets are meant to promote consistency of governance. 


The visibility rules apply at the level of a set of evidence. Based on the visibility rule, we can customize whether to display a set of questions or not. For instance, certain evidence may be necessary only for Governed Bundles classified as high-risk.
Input (evidence)
Evidence is information that is relevant to a policy. In most cases, evidence is a question with an answer. Domino supports different types of evidence, such as radio, textblock, or checkboxes. 
Metric checks (evidence)
One of Domino’s strengths is its system of record. Models trained in Domino can store diagnostic metrics in Domino’s experiment manager. Our policy engine can access these metrics directly, allowing us to define policies where, for example, only models with an accuracy greater than 85 are accepted.  
Scripted checks (evidence)
Scripted checks are centralized scripts used to evaluate information on the Governed Bundle. They can also be used to measure bias consistently in a dataset. 
2.1.3 - Approvals
Approvals are actions that can be added to a policy to request approval from an organization[c][d][e] or an individual.[f] Anyone with project access can request approval.


When requesting approval, the practitioner can choose to select either an individual or an organization, depending on how the policy is defined. If the practitioner selects an individual, a Domino Task will be created and assigned to that person. However, if the practitioner selects an organization, only the organization's owner will be notified. It will then be the owner's responsibility to assign the task to the appropriate person within the organization.
2.1.4 - Classification 
Classification is a top-level variable for a policy that is meant to carry the overall classification of the governed bundle. For example, it could be used in a tiered approach like low, medium, or high risk. 
Classification Rules
Classification supports complex operations using the Go programming language. It uses the values results from one or multiple evidence answers and expects an output of a string or a float. 
2.2 - Governed Bundles
A governed bundle is an abstraction layer mapping a policy to a set of files. This is where the governance policy is applied. A governed bundle can be a single model (AI or ML), a collection of models building an AI system together, or a set of files like data, PDF, and statistical analysis. 


The governed bundle will store all evidence related to the policy it governs and keep the lineage to the relevant attachments.
2.2.1 - Attachments 
Any files from a project that need to be attached to a bundle to be governed by a policy in a specific context.
2.2.2 - Evidence notebook
The collection of questions and answers from a policy for a specific file set. 
________________


3 - Roles and permissions 
A new role - GovernanceAdmin - was added to Domino to ensure the desired level of granularity and control for Governance. GovernanceAdmin is a global role at the same level as a SysAdmin or a CloudAdmin. [g]
3.1 - GovernanceAdmin 
The GovernanceAdmin role manages policies. The GovernanceAdmin has unique permissions to create, edit, and publish policies. In addition to managing policies, the GovernanceAdmin can view the governance dashboard and access the governance APIs.
The SysAdmin[h][i][j][k] (for self-hosted environments) and CloudAdmin (for Domino Cloud environments) have complete access to policy management and the governance dashboard.


________________


4 - Building and managing policies 
Policies can be managed in the Governance Console. 
Once a policy is published, it becomes immutable, ensuring the lineage between a Governed Bundle and the approved policy can be maintained.                                                                                                                                                                                                                                                                          
4.1 - Policy Definition (YAML)
This[l][m] document explains the YAML configuration structure that defines various input fields, automated jobs, metadata, and guidance elements.
4.1.1 - Structure Overview
The YAML configuration consists of a list of items, each representing a different element in the user interface or system configuration. 
Each item has the following common properties:
* `artifactType`: Defines the type of artifact (e.g., input, automatedJob, metadata, guidance)
* `required`: Boolean indicating if the field is mandatory
* `disabled`: Boolean indicating if the field is disabled
The `details` section contains specific properties for each artifact type.
4.1.2 - Stages
Stages represent meaningful phases of work in the project development lifecycle. In order to be published, the policy needs to define at least one stage and one approver. 
yaml
stages:
  - name: stage1
  - name: stage2
* `name`: The name of the stage
4.1.3 - Evidence and evidence sets
Evidence includes inputs, approvals, and scripted checks that should be gathered as part of the governance process within a given stage. 


Evidence sets are logical groupings of evidence and can be made available globally for reuse in other policies. Evidence defined locally cannot be used in other policies.
yaml 
evidenceSet:
  - id: Local.sample
     name: sample local evidence
     description: Describe the sample local evidence
     definition: Define the evidence[n][o][p][q][r][s]
* `local`:  local evidence should include the full definition when appearing for the first time in the policy. It can later be referenced by id when used in the YAML file.
* `name`: name of the evidence.
* `description`: this is where the evidence is described.
* `definition`: this is where artifacts are defined. Guidance artifact types must have a text field under details. Input artifact types must have type and label fields. Each artifact contains one UI element. Supported types include radio, textinput, textarea, select, multiselect, checkbox, date, and numeric.
________________


4.1.4 - Input Artifacts
Input artifacts represent various form elements for user input.
Radio Buttons
yaml
- artifactType: input
  details:
    type: radio
    label: "How would you rate the model risk?"
    options:
      - label: "High"
        value: "High"
      - label: "Medium"
        value: "Medium"
      - label: "Low"
        value: "Low"
    tooltip: "Guidance text"
* `type: radio`: Defines a set of radio buttons
* `label`: The question or prompt for the radio group
* `options`: A list of choices, each with a `label` (displayed text) and `value` (submitted data)
* `tooltip`: Additional information is shown on hover
Text Input
yaml
- artifactType: input
  details:
    type: textinput
    label: "What are the expected business benefits?"
    placeholder: "Explain the benefit"
    helpText: "The text under the input box to help the user"
* `type: textinput`: Defines a single-line text input field.
* `label`: The prompt for the input.
* `placeholder`: Example text is shown when the field is empty.
* `helpText`: Additional guidance is displayed below the input field.
Text Area
yaml
- artifactType: input
  details:
    type: textarea
    label: "What are the expected business benefits?"
    height: 10
    placeholder: "Explain the benefit"
    helpText: "The text under the input box to help the user"
* `type: textarea`: Defines a multi-line text input field
* `height`: Specifies the height of the text area in lines
Select Dropdown
yaml
- artifactType: input
  details:
    type: select
    label: "Please select the base model template."
    options:
      - label: "base model1"
        value: "baseModel1"
      - label: "base model2"
        value: "baseModel2"
* `type: select`: Defines a dropdown selection field
* `options`: A list of choices, similar to radio buttons
________________


Multi-Select
yaml
- artifactType: input
  details:
    type: multiSelect
    label: "Please select the data sets used in the model."
    options:
      - label: "data set1"
        value: "dataset1"
      - label: "data set2"
        value: "dataset2"
      - label: "data set3"
        value: "dataset3"
* `type: multiSelect`: Defines a multi-select dropdown field and allows selection of multiple options
Checkbox Group
yaml
- artifactType: input
  details:
    type: checkbox
    label: "Please select the departments that will use the model?"
    options:
      - label: "Sales"
        value: "DEPT001"
      - label: "Customer Success"
        value: "DEPT002"
* `type: checkbox`: Defines a group of checkboxes and allows selection of multiple options
________________


Date Input
yaml
- artifactType: input
  details:
    type: date
    label: "What is the scheduled release date?"
    startDate: 20240612
    format: ISO8601
* `type: date`: Defines a date input field
* `startDate`: Sets the initial date (format: YYYYMMDD)
* `format`: Specifies the date format (e.g., ISO8601)
Numeric Input
yaml
- artifactType: input
  details:
    type: numeric
    label: "What is the allowed F score for the model to be deployed?"
    min: 0
    max: 1
* `type: numeric`: Defines a numeric input field
* `min` and `max`: Set the allowed range for the input
4.1.5 - Guidance Artifacts
Guidance artifacts provide guidance or information to the user.
yaml
- artifactType: guidance
  details:
    type: textblock
    text: >-
      [Map 1.4](https://ournistpolicyreferenceurl.com) The business value or
      context of business use has been clearly defined or - in the case of
      assessing existing AI systems - re-evaluated

* `type: textblock`: Displays a block of text
* `text`: The content to display - supports Markdown formatting


yaml
- artifactType: guidance
  details:
    type: banner
    text: >-
      [Map 1.4](https://ournistpolicyreferenceurl.com) The business value or
      context of business use has been clearly defined or - in the case of
      assessing existing AI systems - re-evaluated

* `type: banner`: Displays a prominent banner with text
* Useful for important notices or key information
4.1.6 - Approvals 
Approvals are defined under stages. Each approval is defined with a name, a group of specified approvers, and evidence. Approvers must be Domino users or organizations and are specified by the user's or organization's name. In order to be published, a policy needs to define at least one approver and one stage. 
approvers:  
  - model-gov-org  # The name of a Domino user or organization


- name: 'Stage 4: validation sign off'
  approvers:
    - model-gov-org
  evidence:
    id: Local.validation-approval-body
    name: Sign-off
    description: The checklist for approvals
    definition:
      - artifactType: input
        details:
          label: Have you read the model validation reports?
          type: radio
          options:
            - Yes
            - No
* Top-level approvers: required field - default approvers for the policy. The approvers and stage approvers have the right to transition the bundle to the Complete stage and therefore locks the bundle from any further editing.
4.1.7 - Classification
A classification involves using values from artifacts and possibly applying a rule to calculate a composite score known as calculatedValue. 


This calculatedValue is then used to decide whether downstream fields are visible based on the visibilityRule key.  [t][u][v]
yaml


classification:
  rule: 
  artifacts:
    - model-risk  


stages:
  - name: classificationExample
      - id: Local.model-risk
        name: Model Risk
        description: Describe the risk of the model
        definition:
          - artifactType: input
            aliasForClassification: model-risk  
            details:
              label: How would you rate the model risk?
              type: radio
              options:
                - High
                - Low
              tooltip: guidance on how to rate the model risk within the organization
* `classification`: policy level classification
* `rule`: classification rule definition, leave it empty if using the result of the artifact defined below 
* `artifacts`: The artifact alias that is specified in the evidence definition
* `aliasForClassification`: Reference to classification artifacts
Classification rule [w][x]
Classification rules allow the construction of complex operations based on the outcome of multiple pieces of evidence. 
    func() string {
        var sum float64
        for _, value := range inputs {
           sum += value
        }
        if sum >= 1 {
           return "High"
        }
        return "Low"
    }()


### example from Dylan's GSK policy 
classification:
  rule: |
    var decision string


    if classificationInputs["double-prog"] == "Yes" {
      decision += "double-prog "
    }
    if classificationInputs["code-review"] == "Yes" {
      decision += "code-review "
    }
    if classificationInputs["double-parameter"] == "Yes" {
      decision += "double-parameter "
    }
    return decision
  artifacts:
    - double-prog
    - code-review
    - double-parameter




Visibility Rules
Visibility rules apply at an evidence-set level. Based on the visibility rule, we can customize whether to display a set of questions. For example, some evidence might be required only for Governed Bundles classified as high-risk. 


- name: Code Review
  evidenceSet:
    - id: Local.code-review-signoff
      name: Code Review Sign Off
      description: Independent QC - Code Review Sign Off
      visibilityRule: classificationValue == "double-prog code-review double-parameter " || classificationValue == "code-review " || classificationValue == "code-review double-parameter "
      definition:
        - artifactType: input
          details:
            label: Have you validated the code?
            type: radio
            options:
              - Yes
              - No



* `visibilityRule`: Optional, the visibility rule shows or hides evidence based on the classification value. In this example, the evidence set will only be displayed if the classification is High.


Metrics checks
- artifactType: metadata
  details:
    type: modelmetric
    metrics:
      - name: Accuracy
        threshold:
          operator: '>='
          value: 0.8
      - name: Weighted absolute percentage error
        threshold:
          operator: '<='
          value: 0.16

Scripted checks


- artifactType: policyScriptedCheck
  details: {}



Getting Started 
Building a policy 
 
Governing ML & AI and Statistical Analysis
The cornerstone of governance in Domino is the governed bundle. It’s an abstraction that allows the grouping of arbitrary files together. This collection of files might be a single ML model or a component of an AI system. 
A governed bundle can only be governed by one policy, but files can be attached to many governed bundles. [y]
  



Best practices 
1. Define policies that meet your requirements 
2. Group your model and AI System in a Governed Bundle  
3. Use organization instead of individual in your policy 




API definition [z][aa][ab]


Industry specific[ac][ad] use cases (Pharma[ae][af], FSI[ag][ah], Public Sector[ai][aj])
























































##### Placeholder policy [ak][al]
  

# # Each policy is defined by multiple stages, uncomment the sample below for a quick start
# classification:
#   rule: # The rule to determine the classification value, leave it empty if using the result of the artifact defined below.
#   artifacts:
#     - model-risk  # The artifact alias that is specified in the evidence definition
# approvers:  # The approvers and stage approvers have the right to transition the bundle to the Complete stage and therefore locks the bundle from any further editing.
#   - model-gov-org  # The name of a Domino user or organization
# stages:
#   - name: stage1WithoutApproval
#     # There are two types of evidences: the global evidence that is defined and published beforehand and can be used in multiple policies, and the local evidence that is defined in the policy and can only be referenced in the policy only.
#     # The evidence is referenced following the format <Global|Local>.<Evidence-External-Id> where the prefix "Global" indicates this is a global evidence and "Local" indicates this is a policy owned private evidence.
#     evidenceSet:
#     # The evidence below is an example of using a global evidence named type-of-development
#     #  - id: Global.type-of-development
#     #    visibilityRule: classificationValue=="High"  # Optional, the visibility rule is used to show or hide the evidence based on the value of the classification value. Note that classificationValue is a hard-coded variable that represents the classification value.
#       - id: Local.model-risk
#         name: Model Risk
#         description: Describe the risk of the model
#         definition:
#           - artifactType: input
#             aliasForClassification: model-risk    # Used to be referenced in classification.artifacts
#             details:
#               label: How would you rate the model risk?
#               type: radio
#               options:
#                 - High
#                 - Low
#               tooltip: guidance on how to rate the model risk within the organization
#           - artifactType: input
#             details:
#               label: How would you rate the complexity of the model change?
#               type: radio
#               options:
#                 - High
#                 - Low
#           - artifactType: input
#             details:
#               label: To what extent do you expect that the model output will change?
#               type: radio
#               options:
#                 - Major
#                 - Moderate
#                 - Minor
#   - name: stage2WithApproval
#     # An "approval" object contains a list of approvers and one evidence object.
#     # This approval will only work if a user or organization named model-gov-org is defined
#     # approvals:
#     #  - approvers:
#     #      - model-gov-org  # The name of a Domino user or organization
#     #    evidence:
#     #      id: Local.validation-approval-body
#     #      name: Sign-off
#     #      description: The checklist for approvals
#     #      definition:
#     #        - artifactType: input
#     #          details:
#     #            label: Have you read the model validation reports?
#     #            type: radio
#     #            options:
#     #              - Yes
#     #              - No
#     evidenceSet:
#       # The "Local" evidence should have the full definition included when appearing for the first time in the policy and can be referenced by id when using it later in the YAML file.
#       - id: Local.sample
#         name: sample local evidence
#         description: Describe the sample local evidence
#         # Each evidence contains multiple artifacts. The supported artifact types: input, guidance, metadata, policyScriptedCheck
#         definition:
#           # Guidance artifact types must have a "text" field under details. Input artifact types must have "type" and "label" fields, Metadata artifact types must have a "type" field.
#           # Each artifact contains one UI element. The support types for input artifacts: radio, textinput, textarea, select, multiselect, checkbox, date, numeric.
#           # The supported types for metadata artifacts: modelmetric, file.
#           - artifactType: input
#             details:
#               type: radio
#               label: How would you rate the model risk?
#               options:
#                 - label: High
#                   value: High
#                 - label: Medium
#                   value: Medium
#                 - label: Low
#                   value: Low
#               tooltip: company specific risk level classification guidance text
#           - artifactType: input
#             details:
#               type: radio
#               label: What is the type of the business case?
#               options:
#                 - label: New model development
#                   value: new
#                   secondaryDescriptor: secondary
#                   tooltip: Completely new model
#                 - label: Model change
#                   value: revision
#                   secondaryDescriptor: secondary
#                   tooltip: Revision on existing model
#               tooltip: show company specific workflows for each type
#           - artifactType: input
#             details:
#               type: textinput
#               label: What are the expected business benefits?
#               placeholder: Explain the benefits
#               helpText: The text under the input box to help the user
#           - artifactType: input
#             details:
#               type: textarea
#               label: What are the expected business benefits?
#               height: 10
#               placeholder: Explain the benefits
#               helpText: The text under the input box to help the user
#           - artifactType: input
#             details:
#               type: select
#               label: Please select the base model template. Currently only static options are selected. Dynamic options to be defined later.
#               options:
#                 - label: base model1
#                   value: baseModel1
#                 - label: base model2
#                   value: baseModel2
#           - artifactType: input
#             details:
#               type: multiselect
#               label: Please select the data sets used in the model. Currently only static options are selected. Dynamic options to be defined later.
#               options:
#                 - label: data set1
#                   value: dataset1
#                 - label: data set2
#                   value: dataset2
#                 - label: data set3
#                   value: dataset3
#           - artifactType: input
#             details:
#               type: checkbox
#               label: Please select the departments that will use the model?
#               options:
#                 - label: Sales
#                   value: DEPT001
#                 - label: Customer Success
#                   value: DEPT002
#           - artifactType: input
#             details:
#               type: date
#               label: What is the scheduled release date?
#               startDate: 20240612
#               format: ISO8601
#           - artifactType: input
#             details:
#               type: numeric
#               label: What is the allowed F score for the model to be deployed?
#               min: 0
#               max: 1
#           - artifactType: metadata
#             details:
#               type: modelmetric
#               metrics:
#                 - name: Accuracy
#                   threshold:
#                     operator: '>='
#                     value: 0.8
#                 - name: Weighted absolute percentage error
#                   threshold:
#                     operator: '<='
#                     value: 0.16
#           - artifactType: policyScriptedCheck
#             details: {}






[a]it would be nice to have some vertical specific sub-pages / articles.


"Implementing MRM in Domino"


"Implementing GxP and CFR Part 11 compliance..."


etc.


we also need content on the Audit Log
[b]@ahmet.gyger@dominodatalab.com should we keep this in here?
[c]@joyce.zhao@dominodatalab.com @ahmet.gyger@dominodatalab.com after the latest changes, are we still supporting approvals on an org level?
[d]yes. The existing behavior is still the same as what we had for EY demo. @ahmet.gyger@dominodatalab.com Will we still have the organization approver in MS3? My understanding is that you want to expand the organization to be a list of members for DSP to select for submitting approvals.
[e]I've clarified the behavior here: https://docs.google.com/document/d/1Ry6IxlFFjfkmlBPmm6D02EOYxxcqn4Z4BLWK6fenfzQ/edit#heading=h.a02ub011nmn9
[f]should we note that it's a "best practice" to use organizations for approvals? (to prevent having to re-do whole policies/bundles if an individual leaves the complany?)


@ahmet.gyger@dominodatalab.com
_Assigned to ahmet.gyger@dominodatalab.com_
[g]I don't think this is correct...should we say this instead: 


GovernanceAdmin is a global role with some of the permissions of a SysAdmin or CloudAdmin.


@ahmet.gyger@dominodatalab.com
_Assigned to ahmet.gyger@dominodatalab.com_
[h]Might want to put a qualification in there about domino cloud and customer managed environments.
[i]how's that?
[j]how about "The SysAdmin (self-hosted environments) and CloudAdmin (Domino Cloud environments) also have ful l access to policy management and the governance dashboard."
[k]@sandra.wagner@dominodatalab.com I would double check the accuracy of that statement with @ahmet.gyger@dominodatalab.com
1 total reaction
Sandra Wagner reacted with 👍 at 2024-10-02 11:32 AM
[l]@joyce.zhao@dominodatalab.com , @avani.tanna@dominodatalab.com - would appreciate a review of this section of the documentation. I'm still missing the classification and the functions call.
_Assigned to joyce.zhao@dominodatalab.com_
[m]Just flagging that we will be renaming some of these YAML properties because of very recent usability feedback. Might want to revisit in a few days
1 total reaction
Sandra Wagner reacted with 👍 at 2024-09-03 09:28 AM
[n]@avani.tanna@dominodatalab.com , does this look correct to you?
_Assigned to _past_avani.tanna@dominodatalab.com_
[o]@ahmet.gyger@dominodatalab.com @sandra.wagner@dominodatalab.com I haven't had the chance to check indent errors - please look at the placeholder policy definition and that should help get you an example.
[p]which policy definition are we talking about? could you give a link?
[q]If you go to any instance and click on create policy, you will see a placeholder policy which is just commented and there to give you an idea of what all the policy components might look like, for example, https://gov-demo59552.workbench-accessdata-team-sandbox.domino.tech/governance/policy/da849523-926a-45bb-a150-880f6ecf0c92/editor. 


cc @joyce.zhao@dominodatalab.com for more visibility for this section
[r]That link gives me a 403 error
[s]pasted a placeholder policy at the bottom of the doc for reference
[t]We are over using this example  and should actually describe what a classification is from a systematic perspective. 


A classification is a combination of values provided from artifacts and potentially the application of a rule to calculate a composite score in the form of a calculatedValue. This calculatedValue is then used to determine if downstream fields are visible via the visibilityRule key. 


I'm not saying this is the right verbiage or even correct - but i do think we need to be a bit more in-depth in describing what this is and how it works.
[u]I like how you are putting this. The visibilityRule is explained elsewhere and we should keep this separation. 


@sandra.wagner@dominodatalab.com - wdyt?
[v]easy and no worries....i'm reconfiguring it a bit now. 


How's that?
[w]@avani.tanna@dominodatalab.com - can you add the information for classification rules?
_Assigned to _past_avani.tanna@dominodatalab.com_
[x]@ahmet.gyger@dominodatalab.com @sandra.wagner@dominodatalab.com 


Classification rule is incorrect/not following the recent improvements. I am attaching an  example from Dylan's GSK policy - hope that helps. Please modify as you need.
[y]this stuff seems like a repeat of a previous section (the aforementioned "High Level Overview") -
[z]@gabriel.haim@dominodatalab.com - can you link?
_Assigned to gabriel.haim@dominodatalab.com_
[aa]https://github.com/cerebrotech/rai-guardrails-service/blob/main/api/swagger.yaml
[ab]This is not going to be accessible by external users, right?


@sandra.wagner@dominodatalab.com do we have a good way to display a swagger API into our docs?
_Reassigned to sandra.wagner@dominodatalab.com_
[ac]i might actually tuck this part just under the High-level overview
[ad]unless it's going to be long...i that case, I would put a bulleted list under the High-level overview and link each list item to the corresponding use case
[ae]@jim.coates@dominodatalab.com - could you add the Pharma use cases here?
_Assigned to jim.coates@dominodatalab.com_
[af]cc: @ross.sharp@dominodatalab.com
[ag]@bryan.prosser@dominodatalab.com - could you add the FSI use cases here?
_Assigned to bryan.prosser@dominodatalab.com_
[ah]still WIP
[ai]@andrea.lowe@dominodatalab.com - could you add the public sector use cases here?
_Assigned to andrea.lowe@dominodatalab.com_
[aj]still a WIP - unclear about the exact Use Case
[ak]@sandra.wagner@dominodatalab.com as discussed, attaching the placeholder policy for your reference. Hope this helps! @joyce.zhao@dominodatalab.com for more visibility + please feel free to chime in.
[al]thank you so much!!!